{
    "question": "Summarize the following evidence in 2-3 sentences.",
    "content": {
        "source_1": "I took this on Coursera over five weeks and kept a notebook just for the weekly challenges. The instructor had us turn guesses into testable statements, and I actually ran a small A/B test on two landing pages for a neighborhood meal-prep idea. The videos are mostly 8–12 minutes, and the whiteboard sessions made it easy to follow the flow from hypothesis to metric to decision. By week 4 I’d scrapped my original pricing after the data came back soft, and the final project had me present a simple funnel analysis. I didn’t finish with a company, but I did finish with a repeatable checklist for trying ideas without burning cash.",
        "source_2": "Zooming in only on the “challenges”: they felt like busywork. Week 2 asked us to “validate demand” with interviews, but the prompt gave no sampling guidance, so my peer reviews praised five chats with friends as if that proved anything. Week 3’s rubric was a single line about “collecting data,” yet the example solution used a spreadsheet with five entries. I wanted increasing difficulty—maybe a small field experiment by week 4—but the tasks just circled around interviews, a survey, and another survey.",
        "source_3": "Focusing strictly on the instructor: the classroom demos were the clearest part. He took a street-vendor example and showed how to turn a hunch—“students buy more after 3 p.m.”—into a falsifiable statement, then walked through counting passes and logging results. He sketches simple causal diagrams before touching a spreadsheet, and he uses concrete numbers rather than vague advice. The bit where he contrasts “stories that feel right” with results that don’t match intuition stuck with me; it’s delivered without jargon, but you still see the logic step by step.",
        "source_4": "As an overall course, it leans heavily on catchphrases about getting out of the building and “just start,” but the so‑called science rarely goes beyond tiny samples and quick polls. The case studies are short clips with upbeat music, yet the data behind the decisions is barely shown. The peer grading swung wildly—one week I got a 2/10 with no comments, the next week a 10/10 with “nice job.” Quizzes are multiple‑choice recall rather than application. I kept waiting for a full walk‑through of an experiment with real numbers and confidence bounds; instead, the videos move on once the lesson’s slogan lands.",
        "source_5": "On course structure alone: the pacing jumps. Module 1 introduces hypotheses, but Module 2 dives into customer interviews without connecting back to how those answers will be measured later. Several videos end mid-thought and continue in the next clip, making it easy to lose the thread. The forum was the saving grace—other learners shared templates and a better rubric for interviews—but that came from the community, not the syllabus. I finished the certificate, yet I still had to assemble my own sequence of tasks to make the capstone feel coherent."
    }
}