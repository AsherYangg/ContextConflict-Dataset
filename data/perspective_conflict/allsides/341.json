{
    "question": "How could Apple’s dictation glitch—sometimes showing “Trump” when a user says “racist”—affect perceptions of its AI reliability and neutrality, and what steps would best build trust as it rolls out a fix?",
    "content": {
        "source_1": "Tech company blames ‘phonetic overlap’ for problem where US president’s name appears\n\nApple has promised to fix a bug in itsiPhoneautomatic dictation tool after some users reported it had suggested to them “Trump” when they said the word “racist”.\n\nThe glitch was first highlighted in aviral post on TikTok, when the speech-to-text tool sometimes briefly flashed up the word “Trump” when they said “racist”, and was later repeated by others on social media.\n\n“We are aware of an issue with the speech recognition model that powers dictation and we are rolling out a fix,” anApplespokesperson said.\n\nThe company blamed the bug on its tool displaying words that have “phonetic overlap” before the “intended word” is identified, which in this case included words with the “r” consonant.\n\nHowever, the glitch caused outrage among some conservative commentators in the US, who havelong accused big tech companies of political biasagainst those on the right.\n\nThe bug also called into question Apple’s artificial intelligence capabilities, only a day after the company announced a$500bn (£395bn) investment in the US, widely interpreted as a move designed to appeal to Donald Trump’s government.\n\nThe tech company said on Monday that the investment, running over the next four years, would include a giant factory in Texas for artificial intelligence servers and would create about 20,000 research and development jobs across the country.\n\nThe AI announcement came only days after Apple’s chief executive, Tim Cook, reportedly met Trump. The company could face 10% tariffs on its devices, many of which are assembled in China before being imported into the US.\n\nThe maker of the iPhone did manage to secure some waivers on tariffs levied on China during Trump’s first term.\n\nGet set for the working day – we'll point you to all the business news and analysis you need every morning\n\nIt is not the first time Apple has announced a multibillion-dollar investment in the US economy during a Trump administration. In 2018, during his first term in the White House, Apple said that new and ongoing investments would contribute $350bn to the US economy over five years.\n\nSince Trump’s election and his signing ofa slew of executive ordersoverturning diversity, equity and inclusion measures in the federal government, many in the tech sector have followed suit witha rollback of similar schemes– including Google, Amazon and Meta. However, on Tuesday Apple shareholdersvoted down a proposalurging the company to drop its own DEI programmes.",
        "source_2": "Then€69per month.\nComplete digital access to quality FT journalism on any device. \nCancel anytime during your trial.\n\nEssential digital access to quality FT journalism on any device. Pay a year upfront and save 20%.\n\nComplete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.\n\nComplete digital access to quality analysis and expert insights, complemented with our award-winning Weekend Print edition.\n\nCheck whether you already have access via youruniversityororganisation.\n\nDiscover all the plans currently available in your country\n\nDigital access for organisations. Includes exclusive features and content.\n\nSee why over a million readers pay to read the Financial Times.",
        "source_3": "iPhone’s voice-to-text feature briefly shows \"Trump\" when a user says \"Racist.\"\n\nApple’s iPhonevoice-to-text feature is sparking controversy after a viral TikTok video showed a user speaking the word \"racist,\" which at first showed up as \"Trump\" before switching back to \"racist.\"\n\nFox News Digital was able to replicate the issue multiple times. The voice-to-text dictation feature was observed briefly flashing \"Trump\" when a user said \"racist\" before it quickly changed back to \"racist\" – just like in the viral TikTok video.\n\nHowever, \"Trump\" did not appear every time a user said \"racist.\"\n\nThe voice-to-text feature also wrote words like \"reinhold\" and \"you\" when a user said \"racist.\" Most of the time, the feature accurately wrote \"racist.\"\n\nAMAZON ALEXA GIVES STARKLY DIFFERENT ANSWERS WHEN ASKED WHY TO VOTE FOR TRUMP VERSUS KAMALA HARRIS\n\nApple's iPhone voice-to-text feature appears to write \"Trump\" occasionally when a user says \"racist.\"(Fox News)\n\nAn Apple spokesperson said Tuesday that the company is addressing the issue.\n\n\"We are aware of an issue with the speech recognition model that powers Dictation, and we are rolling out a fix as soon as possible,\" the spokesperson said.\n\nApple says that the speech recognition models that power dictation may temporarily display words with some phonetic overlap, before landing on the correct word. The bug affects other words with an \"r\" consonant when dictated, Apple says.\n\nAPPLE UNVEILS HISTORIC $500B INVESTMENT IN US MANUFACTURING\n\nThis is not the first time technology has sparked controversy over what was perceived as a slight againstPresident Donald Trump.\n\nA video went viral in September showing the Amazon Alexa virtual assistant explaining reasons for voting for then-Vice President Kamala Harris while refusing to provide similar responses for Trump.\n\nRepresentatives from the online shopping giant briefed staffers from the House Judiciary Committee about the incident and explained that Alexa uses pre-programmed manual overrides created by Amazon’s information team to respond to certain prompts from users, according to a source familiar with the briefing.\n\nFor example, Alexa would tell users who asked for reasons to vote for Trump or then-President Joe Biden, \"I cannot provide content that promotes this specific political party or candidate.\"\n\nPrior to the release of the viral video, Amazon had only programmed manual overrides for Biden and Trump, failing to add Harris because very few users were asking Alexa about reasons to vote for her, the source said.\n\nREP. JIM JORDAN REQUEST AMAZON BRIEFING OVER ALEXA'S TRUMP CENSORSHIP\n\nThe Amazon Alexa virtual assistant previously explained reasons for voting for then-Vice President Kamala Harris while refusing to provide similar responses for then-former President Donald Trump.(Amazon)\n\nAmazon became aware of the issue with Alexa's pro-Harris responses within one hour of the video being posted on X and going viral. The company fixed the issue with amanual overridefor such questions about Harris within two hours of the video going up, according to the source.\n\nBefore the fix was deployed, Fox News Digital prompted Alexa with questions asking for reasons to vote for Harris and received a response saying that \"she is a female of color with a comprehensive plan to address racial injustice and inequality throughout the country.\"\n\nTRUMP, MUSK ENDORSE VIVEK RAMASWAMY FOR OHIO GOVERNOR\n\nThe source said that Amazon apologized for Alexa's display ofpolitical biasat the briefing and said that while it has a policy that aims to prevent Alexa from \"having a political opinion\" or \"bias for or against a particular party or particular candidate… obviously we are here today because we did not meet that bar in this incident.\"\n\nThe tech giant has since audited its system and has manual overrides in place for all candidates and a number of election-related prompts. Previously, Alexa only had manual overrides forpresidential candidates.\n\nFOX Business’ Eric Revell, Hillary Vaugh, and Chase Williams contributed to this report.\n\nGreg Wehner is a breaking news reporter for Fox News Digital.\n\nStory tips and ideas can be sent to Greg.Wehner@Fox.com and on Twitter @GregWehner.\n\nGet a daily look at what’s developing in science and technology throughout the world."
    }
}