{
    "question": "What is the name of the world's fastest supercomputer?",
    "content": {
        "source_1": "After experimenting with metrics based on processor count in 1992, the idea arose at the University of Mannheim to use a detailed listing of installed systems as the basis. In early 1993, Jack Dongarra was persuaded to join the project with his LINPACK benchmarks. A first test version was produced in May 1993, partly based on data available on the Internet, including the following sources:[4][5]\n\"List of the World's Most Powerful Computing Sites\" maintained by Gunter Ahrendt[6]\nDavid Kahaner, the director of the Asian Technology Information Program (ATIP);[7] published a report in 1992, titled \"Kahaner Report on Supercomputer in Japan\"[5] which had an immense amount of data.[citation needed]\nThe information from those sources was used for the first two lists. Since June 1993, the TOP500 is produced bi-annually based on site and vendor submissions only. Since 1993, performance of the No. 1 ranked position has grown steadily in accordance with Moore's law, doubling roughly every 14 months. In June 2018, Summit was fastest with an Rpeak[8] of 187.6593 PFLOPS. For comparison, this is over 1,432,513 times faster than the Connection Machine CM-5/1024 (1,024 cores), which was the fastest system in November 1993 (twenty-five years prior) with an Rpeak of 131.0 GFLOPS.[9]\nTwo computers which first appeared on the list in 2018 were based on architectures new to the TOP500.",
        "source_2": "Supercomputers work based on the same principles as everyday computers, but their performance levels are much higher and they look more like the classic mainframes of old. Unlike normal desktop PCs or laptops, they process massive data sets and perform calculations at incredible speeds. They're the fastest computers in the world, according to IBM, and require a massive amount of infrastructure to operate — including advanced cooling systems.\n Architecturally, they are also fitted with many more components than normal PCs. Your laptop might have one central processing unit (CPU) and one graphics processing unit (GPU), but one supercomputer may have thousands upon thousands of CPUs and GPUs — each of them considerably more powerful than those you find off the shelf.\n Their performance is also measured using floating-point operations per second (FLOPS) — where one floating-point operation is a mathematical calculation. The most powerful supercomputer in the world now exceeds 1 exaFLOP — 1 quintillion (1018) FLOPS — while normal PCs and laptops usually have power of several hundred gigaFLOPS — 1 trillion (109) FLOPS. We refer to machines like this as exascale supercomputers.\n Because they can work with massive amounts of data and process calculations incredibly fast, scientists often use supercomputers to crack problems in drug and material discovery. Supercomputers can also make predictions — like forecasting the weather — and even learn how to play chess, like IBM's classic Deep Blue supercomputer in 1997.\n Based on the latest TOP500 rankings, here are the seven most powerful supercomputers online today.\n Currently top of the list, Frontier — built by supercomputing giant HPE Cray — became the first exascale computer in the world when it went online in 2022. Scientists initially planned to use Frontier for cancer research, drug discovery, nuclear fusion, exotic materials, designing superefficient engines and modeling stellar explosions, according to IEEE Spectrum.\n In the coming years, scientists will use Frontier to design new transport and medicine technologies, reported MIT Technology Review.",
        "source_3": "Following years of development, the US' El Capitan supercomputer now ranks as the world's fastest, dethroning the previous champion, Frontier, another US exascale computer.\n In a recent verified test, El Capitan achieved 1.742 exaFLOPs of performance or 1.742 quintillion calculations per second, according to Lawrence Livermore National Laboratory in California, where the supercomputer is based.\nTop500, which benchmarks and catalogs the world’s fastest supercomputers, previously ranked Frontier and Aurora as the two top machines. In this latest round, the AMD-powered Frontier was benchmarked at 1.35 exaFLOPs, while its top theoretical speed was rated at 2.05 exaFLOPs. The same machine can also access up to 24 megawatts of power.\n In contrast, El Capitan—which also uses AMD chips—promises a peak performance of 2.79 exaFLOPs over nearly 30 megawatts of electricity. The machine also boasts a \"22-fold peak increase\" over Sierra, which was the world’s second-fastest supercomputer in 2018 but slipped to the 12th spot in June.\n \"Complex, high-resolution 3D simulations that would take weeks or months on Sierra will be done in just hours or days on El Capitan, leading to previously unimaginable insights,” the lab adds.\n (Top500)\nTop500 adds that El Capitan features \"11,039,616 combined CPU and GPU cores and is based on AMD 4th generation EPYC processors with 24 cores at 1.8GHz and AMD Instinct MI300A accelerators.\" For comparison, the second-place Frontier boasts 9 million combined cores.\n The news comes after the US government funded the development of three \"exascale\" supercomputers—El Capitan, Frontier, and the Intel-powered Aurora—taking the technology to the next level.",
        "source_4": "Verified at 1.742 exaFLOPs (1.742 quintillion calculations per second) on the High Performance Linpack — the standard benchmark used by the Top500 organization to evaluate supercomputing performance — El Capitan is the fastest computing system ever benchmarked. The system has a total peak performance of 2.79 exaFLOPs. The Top500 list was released at the 2024 Supercomputing Conference (SC24) in Atlanta.\n As NNSA’s first exascale supercomputer, El Capitan is a premier resource for the NNSA Tri-Labs — LLNL, and Los Alamos and Sandia National Laboratories — to advance nuclear weapon science and scientific discovery, providing the vast computational power necessary to ensure the safety, security and reliability of the nation’s nuclear deterrent without nuclear testing. This state-of-the-art system marks a monumental leap forward in HPC, enabling unprecedented modeling and simulation capability essential for NNSA’s Stockpile Stewardship Program that certifies the U.S. nuclear stockpile, and other critical nuclear security missions such as nonproliferation and counterterrorism.\n “El Capitan’s introduction continues the capability advancement needed to sustain our stockpile without returning to explosive nuclear testing. This computational capability, backed by decades of data, expertise and code development is the heart of science-based stockpile stewardship,” said Jill Hruby, Department of Energy (DOE) under secretary for nuclear security and NNSA administrator. “We will continue to invest in the technological and scientific infrastructure necessary to underpin the nuclear security enterprise.”\n NNSA Tri-Lab scientists will utilize El Capitan’s speed and unparalleled capabilities to further advance NNSA’s core mission of maintaining an aging stockpile while simultaneously pursuing weapon modernization such as the W87-1 and W93 warheads currently under development. El Capitan will realize a multi-decade goal to model weapon performance and safety in high-fidelity resolution with quantified uncertainties using codes that have been developed and tuned for exascale over the past decade.",
        "source_5": "A supercomputer is a type of computer with a high level of performance as compared to a general-purpose computer. The performance of a supercomputer is commonly measured in floating-point operations per second (FLOPS) instead of million instructions per second (MIPS). Since 2022, supercomputers have existed which can perform over 1018 FLOPS, so called exascale supercomputers.[3] For comparison, a desktop computer has performance in the range of hundreds of gigaFLOPS (1011) to tens of teraFLOPS (1013).[4][5] Since November 2017, all of the world's fastest 500 supercomputers run on Linux-based operating systems.[6] Additional research is being conducted in the United States, the European Union, Taiwan, Japan, and China to build faster, more powerful and technologically superior exascale supercomputers.[7]\nSupercomputers were introduced in the 1960s, and for several decades the fastest was made by Seymour Cray at Control Data Corporation (CDC), Cray Research and subsequent companies bearing his name or monogram. The first such machines were highly tuned conventional designs that ran more quickly than their more general-purpose contemporaries. Through the decade, increasing amounts of parallelism were added, with one to four processors being typical. In the 1970s, vector processors operating on large arrays of data came to dominate. A notable example is the highly successful Cray-1 of 1976. Vector computers remained the dominant design into the 1990s. From then until today, massively parallel supercomputers with tens of thousands of off-the-shelf processors became the norm.[9][10]\nThe US has long been the leader in the supercomputer field, first through Cray's almost uninterrupted dominance of the field, and later through a variety of technology companies. Japan made major strides in the field in the 1980s and 1990s, with China becoming increasingly active in the field.",
        "source_6": "Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript."
    },
    "answer": "EL-Capitan "
}